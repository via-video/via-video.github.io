<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Project webpage for fairy-video2video">
  <meta property="og:title" content="fairy-video2video"/>
  <meta property="og:description" content="Project webpage for fairy-video2video"/>
  <meta property="og:url" content="https://fairy-video2video.github.io/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="Diffusion Models, video-to-video, generative AI">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Fairy: Fast Parallelized Instruction-Guided Video-to-Video Synthesis</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  <link rel="stylesheet" href="./supp/swiper-bundle.min.css">
  <link rel="stylesheet" href="https://unicons.iconscout.com/release/v4.0.0/css/line.css" />
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</head>

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Scrollable Table with Arrow Buttons</title>
  <style>
    .page-container {
      width: 1200px;
      min-height: 1000px;
      margin: 0 auto;
      text-align: left;
      padding-top: 5em;
      padding-left: 1em;
      padding-right: 1em;
      padding-bottom: 1em;
      height: auto;
    }

    .scrollable-table-container {
      display: flex;
      align-items: center;
    }

    #scrollableTableWrapper {
      overflow-x: auto;
      overflow-y: hidden;
      white-space: nowrap;
    }

    table {
      border-collapse: collapse;
      margin: auto;
      display: table;
      border-collapse: separate;
      box-sizing: border-box;
      text-indent: initial;
      line-height: normal;
      font-weight: normal;
      font-size: medium;
      font-style: normal;
      color: -internal-quirk-inherit;
      text-align: start;
      border-spacing: 2px;
      border-color: gray;
      white-space: normal;
      font-variant: normal;
    }

    .last-updated {
      position: absolute;
      top: 0;
      right: 0;
      padding: 10px;
      color: black;
      /* text color */
      font-size: 1.0em;
      z-index: 1000;
      /* ensures it's on top of other elements */
    }

    .container-1 {
      height:750px;
    }

    .container-2{
      height:550px;

    }

    .video-container-character {
      position: relative;
      overflow: hidden;
      margin-left: auto;
      margin-right: auto;
      height: 100%;
      padding: 0;
    }

    .video-container-stylizaton {
      position: relative;
      overflow: hidden;
      margin-left: auto;
      margin-right: auto;
      height: 100%;
      padding: 0;
    }

    .swiper-button-next::after,
    .swiper-button-prev::after {
      content: '';
    }

    .video-container-character .swiper-button-next,
    .video-container-character .swiper-button-prev {
      top: 23rem;
      outline: none;
    }

    .video-container-stylizaton .swiper-button-next,
    .video-container-stylizaton .swiper-button-prev {
      top: 15rem;
      outline: none;
    }


    .swiper-icon {
      font-size: 4rem;
      color: black;
    }
    .video-size {
    height: 335px;
    }
    .video-size-2 {
    height: 250px;
    }
  </style>
</head>



<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">VIA: A Spatiotemporal Video Adaptation Framework for Global and Local Video Editing</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://g-jing.github.io">Jing Gu</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://yuwfan.github.io/">Yuwei Fang</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://universome.github.io/">Ivan Skorokhodov</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://peterwonka.net/">Peter Wonka</a><sup>3</sup>,</span>
            <span class="author-block">
              <a href="https://xinyadu.github.io/">Xinya Du</a><sup>4</sup>,</span>
            <span class="author-block">
              <a href="http://www.stulyakov.com/">Sergey Tulyakov</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://eric-xw.github.io/">Xin Eric Wang</a><sup>1</sup>,</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of California, Santa Cruz,</span>
            <span class="author-block"><sup>2</sup>Snap Research,</span>
            <span class="author-block"><sup>3</sup>KAUST,</span>
            <span class="author-block"><sup>4</sup>University of Texas at Dallas</span>
          </div>
          
          <!-- <br>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><b style="color:#e08ba0; font-weight:normal"> <b>Under Review</b> </b></span>
          </div> -->

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->

              <span class="link-block">
                <a href="http://arxiv.org/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="http://arxiv.org/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/eric-ai-lab/via-video"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code, to be released</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- 
<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <source src="static/video/merged.mov" type="video/mp4">
      </video>
    </div>
  </div>
</section>
<!-- End teaser video -->

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Video editing stands as a cornerstone of digital media, from entertainment and education to professional communication. However, previous methods often overlook the necessity of comprehensively understanding both global and local contexts, leading to inaccurate and inconsistency edits in the spatiotemporal dimension, especially for long videos. In this paper, we introduce VIA, a unified spatiotemporal VIdeo Adaptation framework for global and local video editing, pushing the limits of consistently editing minute-long videos. First, to ensure local consistency within individual frames, the foundation of VIA is a novel test-time editing adaptation method, which adapts a pre-trained image editing model for improving consistency between potential editing directions and the text instruction, and adapts masked latent variables for precise local control. Furthermore, to maintain global consistency over the video sequence, we introduce spatiotemporal adaptation that adapts consistent attention variables in key frames and strategically applies them across the whole sequence to realize the editing effects. Extensive experiments demonstrate that, compared to baseline methods, our VIA approach produces edits that are more faithful to the source videos, more coherent in the spatiotemporal context, and more precise in local control. More importantly, we show that VIA can achieve consistent long video editing in minutes, unlocking the potentials for advanced video editing tasks over long video sequences. 
          </p>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{gu2024via,
      title={VIA: A Spatiotemporal Video Adaptation Framework for Global and Local Video Editing}, 
      author={Jing Gu, Yuwei Fang, Ivan Skorokhodov, Peter Wonka, Xinya Du, Sergey Tulyakov, Xin Eric Wang},
      year={2024},
      journal={arXiv preprint}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is adapted from <a rel="license"
            href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> and <a rel="license"
            href="https://gligen.github.io/">GLIGEN</a>, licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html> -->
